# ğŸ‡»ğŸ‡³ Dia TTS â€“ Fine-Tuning Vietnamese

Highâ€‘quality Vietnamese speech generation on top of Nari Labsâ€™ DIA 1.6B. This repo provides an unofficial fineâ€‘tune enabling natural Vietnamese with controllable style, multiâ€‘speaker accents, and a friendly Gradio demo.
---

âš ï¸ Status: Community release. Upstream DIA currently ships English generation; this project adds Vietnamese via fineâ€‘tuning. Follow ethical use guidelines below.
- Maintainer: Tuan Anh â€” AI/ML Researcher @ Appota SRD (R&D Department)
- Compute: Trained and developed on Appotaâ€™s server infrastructure

## Features

- âœ… Fine-tune model Dia 1.6B with Vietnamese Dataset
- âœ… Support single speaker and multispeaker with various Vietnamese accent ( Nort-male, South-male, North-female and South-female)
- âœ… Adjusting voice generate by `temperature`, `top_p`, `cfg_scale`, etc.
- âœ… Friendly Gradio Inference
- âœ… Speed up by `torch.compile`, `bfloat16`, 8-bit optimizer
---
- You can try demo at : https://huggingface.co/spaces/cosrigel/Dia-Vietnamese
- You can use our finetune model at : https://huggingface.co/cosrigel/dia-finetuning-vnese
---

## Data Preparation for Finetuning model
- Audio: mono 44.1 kHz WAV/FLAC; perâ€‘utterance 3â€“20 s; peakâ€‘normalized.
- Dataset finetuned : capleaf/viVoice
- Total duration: 1,016.97 hours

### Training Configuration:
- Base model : nari-labs/Dia-1.6B
- GPU : NVIDIA RTX A6000
- You can use our checkpoint to use the inference at : https://huggingface.co/cosrigel/dia-finetuning-vnese

## Inference Tips (Vietnamese)
- Transcripts: begin with [01] or [KienThucQuanSu] then text
- For example: [KienThucQuanSu] Thá»§ tÆ°á»›ng cÅ©ng yÃªu cáº§u cÃ¡c Bá»™, cÆ¡ quan trung Æ°Æ¡ng, Ä‘á»‹a phÆ°Æ¡ng tÄƒng cÆ°á»ng cÃ´ng tÃ¡c thanh tra, kiá»ƒm tra viá»‡c sáº¯p xáº¿p, xá»­ lÃ½ tÃ i sáº£n trÆ°á»›c, trong vÃ  sau khi sáº¯p xáº¿p tá»• chá»©c bá»™ mÃ¡y, sáº¯p xáº¿p Ä‘Æ¡n vá»‹ hÃ nh chÃ­nh.
- You can lookup the speaker ID in speaker table ID which is already existed in Gradio Inference
<img width="1545" height="903" alt="Screenshot 2025-08-16 at 09 53 21" src="https://github.com/user-attachments/assets/42a24781-0aaf-402d-aa37-901f0046c9cc" />

## Future Feature Improve
- â˜ Increase the quality of voice-cloning
- â˜ Add emotion to dataset and model so you can you emotion's tag like : [cÆ°á»i], [khÃ³c], [ho],...
- â˜ Adjust the voice of multispeaker so they can sound like they're all in one room speaking to each other.

## Ethics & Responsible Use
- Obtain consent for any real personâ€™s voice.
- Disclose synthetic audio in production settings.
- No impersonation, harassment, or deceptive content.

## ğŸ› ï¸ Setup

```bash
git clone https://github.com/TuananhCR/Dia-Finetuning-Vietnamese
cd dia-vietnamese
python -m venv .venv
source .venv/bin/activate
pip install -e .
```
## Acknowledgements
- Appota SRD (R&D Department) â€” compute & infrastructure support for training and development
- Nari Labs â€“ DIA (architecture & checkpoints)
- Descript Audio Codec (DAC) for discrete audio tokens
- Hugging Face Transformers/PEFT/Accelerate

## Citation
```
If you use this work, please cite the upstream DIA model and this repository.
@misc{Dia-Finetuning-Vietnamese,
  title        = {DIA Vietnamese Fine-Tuning} ,
  author       = {Cos Rigel},
  year         = {2025},
  howpublished = {GitHub repository},{Huggingface repository}
  url          = {https://github.com/TuananhCR/Dia-Finetuning-Vietnamese}
}
```
